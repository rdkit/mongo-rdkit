{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substructure Search Benchmarking\n",
    "\n",
    "These benchmarks were originally run on an early 2015 MacBook Pro with a 2.7 GHz dual-core i5 processor and 8GB of memory. \n",
    "\n",
    "In addition to the dependencies listed below, they make use of three sets of fragments and patterns you can find in `mongordkit/data`. All of the large chemical databases that we search against are constructed from ChEMBL_27. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random, gzip, time, mongordkit, pymongo, rdkit, matplotlib\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Avalon import pyAvalonTools\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import rdBase\n",
    "from rdkit import DataStructs\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import sys\n",
    "import pandas as pd\n",
    "from statistics import mean, median\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from mongordkit.Database import write\n",
    "from mongordkit.Search import similarity\n",
    "from mongordkit.Search import substructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Setup\n",
    "Here we set up a database called `test` that will hold our molecules. We will construct 1 collection called `molecules_100K` to hold the first 100,000 molecules in the ChEMBL_27 dataset and a collection called `molecules_1M` to hold the first 1,000,000 molecules in the ChEMBL_27 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client that will connect to the database.\n",
    "client = pymongo.MongoClient()\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "populating mongodb collection with compounds from chembl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:22:20] Warning: conflicting stereochemistry at atom 11 ignored.\n",
      "RDKit WARNING: [15:45:12] Warning: conflicting stereochemistry at atom 14 ignored.\n",
      "RDKit WARNING: [16:15:11] Warning: conflicting stereochemistry at atom 10 ignored.\n",
      "RDKit WARNING: [16:15:11] Warning: conflicting stereochemistry at atom 10 ignored.\n",
      "RDKit WARNING: [16:15:40] Warning: conflicting stereochemistry at atom 10 ignored.\n",
      "RDKit WARNING: [16:15:40] Warning: conflicting stereochemistry at atom 10 ignored.\n",
      "RDKit WARNING: [16:26:44] Warning: conflicting stereochemistry at atom 6 ignored.\n",
      "RDKit WARNING: [16:26:44] Warning: conflicting stereochemistry at atom 6 ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101001 molecules successfully imported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101001"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the first 100,000 compounds to molecules_100K. \n",
    "write.writeFromSDF(db.molecules_100K, '../../../chembl_27.sdf', 'test', reg_option='standard_setting', \n",
    "                   index_option='inchikey', chunk_size=1000, limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the first 1,000,000 compounds to molecules_1M.\n",
    "write.writeFromSDF(db.molecules_1M, '../../../chembl27_sdf', 'test', reg_option='standard_setting', \n",
    "                   index_option='inchikey', chunk_size=1000, limit=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In molecules_100K: 101000 documents\n",
      "In molecules_1M: 0 documents\n"
     ]
    }
   ],
   "source": [
    "# Let's ensure that there are actually 100,000 and 1M documents in these collections, respectively.\n",
    "print(f\"In molecules_100K: {db.molecules_100K.count_documents({})} documents\")\n",
    "print(f\"In molecules_1M: {db.molecules_1M.count_documents({})} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Set Setup\n",
    "For our queries, we'll use three sets of patterns identified by Greg Landrum in one of his [blog posts](http://rdkit.blogspot.com/2013/11/fingerprint-based-substructure.html) on substructure searching and discussed in this [mailing list](http://www.mail-archive.com/rdkit-discuss@lists.sourceforge.net/msg02066.html) and this [presentation](http://www.hinxton.wellcome.ac.uk/advancedcourses/MIOSS%20Greg%20Landrum.pdf). They are: \n",
    "- Fragments: 500 diverse molecules taken from the ZINC Fragments set\n",
    "- Leads: 500 diverse molecules taken from the ZINC Lead-like set\n",
    "- Pieces: 823 pieces of molecules obtained by doing a BRICS fragmentation of some molecules from the pubchem screening set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../../data/zinc.frags.500.q.smi')\n",
    "fragments = [Chem.MolFromSmiles(line.split()[0]) for line in f]\n",
    "f.close()\n",
    "\n",
    "f = open('../../data/zinc.leads.500.q.smi')\n",
    "leads = [Chem.MolFromSmiles(line.split()[0]) for line in f]\n",
    "f.close()\n",
    "\n",
    "f = open('../../data/fragqueries.q.txt')\n",
    "pieces = [Chem.MolFromSmiles(line) for line in f]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking\n",
    "### Naive Substructure Search\n",
    "`substructure.SubSearchNaive` is a search that simply loops through the dataset and checks for a substructure match on each molecule. This method is not directly benchmarked here because searching through a single molecule takes upward of 5 seconds; this means that it is far too slow to feel directly interactive.\n",
    "### Substructure Search with Fingerprint Screening\n",
    "Instead, we will benchmark the standard `SubSearch`, which makes use of fingerprint screening to dramatically increase efficiency. First, we want to see what kinds of times we are dealing with. For each of our query sets, we will search all of their elements against `molecules_100K` and `molecules_1M`, then return the median and mean query times in seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_query_set(query_set, dataset):\n",
    "    results = []\n",
    "    for pattern in query_set:\n",
    "        start = time.time()\n",
    "        substructure.SubSearch(pattern, dataset)\n",
    "        end = time.time()\n",
    "        results.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark for search of all three query sets against 100K and 1M.\n",
    "# This should take around five minutes; these calls can be split up if necessary.\n",
    "frag_times_100K = benchmark_query_set(fragments, db.molecules_100K)\n",
    "frag_times_1M = benchmark_query_set(fragments, db.molecules_1M)\n",
    "lead_times_100K = benchmark_query_set(leads, db.molecules_100K)\n",
    "lead_times_1M = benchmark_query_set(leads, db.molecules_1M)\n",
    "pieces_times_100K = benchmark_query_set(pieces, db.molecules_100K)\n",
    "pieces_times_1M = benchmark_query_set(pieces, db.molecules_1M)\n",
    "\n",
    "results = [frag_times_100K, frag_times_1M, lead_times_100K, lead_times_1M, pieces_times_100K, pieces_times_1M]\n",
    "\n",
    "means = [mean(times) for times in results]\n",
    "medians = [median(times) for times in results]\n",
    "\n",
    "data = {'mean': means, 'median': medians}\n",
    "df = pd.DataFrame(data, index =['fragments', 'leads', 'pieces']) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Size\n",
    "Now we are also interested in learning how this substructure search scales according to the size of the dataset. In order to do so, we will conduct the searches with the same query set against datasets of increasing size, from 1000 - 10,000 molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_rdkit_beta",
   "language": "python",
   "name": "py37_rdkit_beta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
